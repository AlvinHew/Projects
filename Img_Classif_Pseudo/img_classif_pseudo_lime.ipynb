{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1020,"status":"ok","timestamp":1664673700050,"user":{"displayName":"Alvin Hew Xin Yao","userId":"07976192354382836143"},"user_tz":-480},"id":"YOGviieVs_ad","colab":{"base_uri":"https://localhost:8080/"},"outputId":"298c0a5c-6eda-4af0-ca14-9002c74209ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tesla T4\n","2\n"]}],"source":["#ADD\n","import torch, torchvision\n","import matplotlib.pyplot as plt\n","if torch.cuda.is_available():\n","  print(torch.cuda.get_device_name(0))\n","import multiprocessing\n","NUM_WORKERS = multiprocessing.cpu_count()\n","print(NUM_WORKERS)"]},{"cell_type":"markdown","metadata":{"id":"EVgrPb3HhJUT"},"source":["# Get Data\n","Notes: if the links are dead, you can download the data directly from Kaggle and upload it to the workspace, or you can use the Kaggle API to directly download the data into colab.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2811,"status":"ok","timestamp":1664673702841,"user":{"displayName":"Alvin Hew Xin Yao","userId":"07976192354382836143"},"user_tz":-480},"id":"mEB5vUmktXzS","outputId":"a4c73124-db90-4156-c26c-4b7da20ff096"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#ADD\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1664673702841,"user":{"displayName":"Alvin Hew Xin Yao","userId":"07976192354382836143"},"user_tz":-480},"id":"B8YIjlxg3BLV","outputId":"8692ddc0-92df-4824-880c-0e5c92834f01"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Research Courses/Github\n","2022ML_HW3_Image_Classification.ipynb  lime.ipynb\n","baseline_40_best.ckpt\t\t       pretrain_40_best.ckpt\n","baseline_40_log.txt\t\t       pretrain_40_log.txt\n","food11\t\t\t\t       pretrain_best.ckpt\n"]}],"source":["%cd 'drive/MyDrive/Research Courses/Github'\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EAO6dg9eVaU_"},"outputs":[],"source":["#! wget https://www.dropbox.com/s/6l2vcvxl54b0b6w/food11.zip\n","#! wget -O food11.zip \"https://github.com/virginiakm1988/ML2022-Spring/blob/main/HW03/food11.zip?raw=true\" #corrupted file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HEsBm1lkhGmk"},"outputs":[],"source":["#! unzip -q 'food11.zip' #-q = quiet, or else will output \"inflating: training/0_850.jpg\" & \"inflating: test/850.jpg\" etc"]},{"cell_type":"markdown","metadata":{"id":"n5ceUnRihL-f"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ay3WkYnHVaVE"},"outputs":[],"source":["#_exp_name = \"baseline_40\"   #pretrained = False,  semi = False\n","#_exp_name = \"pretrain_40\"  #pretrained = True,   semi = False\n","_exp_name = \"pseudo_40\"    #pretrained = True,   semi = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CwOGtRWHVaVF"},"outputs":[],"source":["# Import necessary packages.\n","import numpy as np\n","import pandas as pd\n","#import torch\n","import os\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from PIL import Image\n","# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n","from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n","from torchvision.datasets import DatasetFolder, VisionDataset\n","\n","#from tqdm.auto import tqdm \n","from tqdm import tqdm \n","#AssertionError can only test a child process, change 'tqdm.auto' to 'tqdm'\n","#ref: https://discuss.pytorch.org/t/error-while-multiprocessing-in-dataloader/46845\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8kJm9GekVaVH"},"outputs":[],"source":["myseed = 6666  \n","random.seed(myseed) #ADD\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(myseed)\n","torch.manual_seed(myseed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(myseed)"]},{"cell_type":"markdown","metadata":{"id":"d9MVtgbSVaVH"},"source":["## **Transforms**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jvI3Xmq4VaVJ"},"outputs":[],"source":["# Normally, We don't need augmentations in testing and validation.\n","# All we need here is to resize the PIL image and transform it into Tensor.\n","test_tfm = transforms.Compose([\n","    transforms.Resize((128, 128)),\n","    transforms.ToTensor(),\n","])\n","\n","# However, it is also possible to use augmentation in the testing phase.\n","# You may use train_tfm to produce a variety of images and then test using ensemble methods\n","train_tfm = transforms.Compose([\n","    # Resize the image into a fixed shape (height = width = 128)\n","    transforms.Resize((128, 128)),\n","    # You may add some transforms here.\n","    # ToTensor() should be the last one of the transforms.\n","    transforms.ToTensor(),\n","])\n"]},{"cell_type":"markdown","metadata":{"id":"D0ivMf-jVaVK"},"source":["## **Datasets**\n","The data is labelled by the name, so we load images and label while calling '__getitem__'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xBdtPhKwVaVL"},"outputs":[],"source":["class FoodDataset(Dataset):\n","\n","    #def __init__(self,path,tfm=test_tfm,files = None):\n","    def __init__(self,paths,tfm=test_tfm,files = None, label=True): #ADD\n","        super(FoodDataset).__init__()\n","        #self.path = path  #ADD\n","        #self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")]) #ADD\n","        #            why sort?\n","        self.files = paths\n","        if files != None:\n","            self.files = files\n","        #print(f\"One {path} sample\",self.files[0])\n","        self.transform = tfm\n","        self.label = label\n","  \n","    def __len__(self):\n","        return len(self.files)\n","  \n","    def __getitem__(self,idx):\n","        fname = self.files[idx]\n","        im = Image.open(fname)\n","        im = self.transform(im)\n","        #im = self.data[idx]\n","        try:\n","            label = int(fname.split(\"/\")[-1].split(\"_\")[0]) if self.label else -1\n","        except:\n","            label = -1 # test has no label\n","        return im,label"]},{"cell_type":"code","source":["class CreateDataset(Dataset):\n","    def __init__(self, x, y=None, transform=None): \n","      self.data = [Image.fromarray(i.cpu().numpy().astype('uint8'), 'RGB') for i in x]\n","      self.label = y.cpu().numpy()\n","      self.transform = transform\n","\n","    def __getitem__(self, idx):\n","      return self.transform(self.data[idx]), self.label[idx]\n","        \n","    def __len__(self):\n","        return len(self.data)"],"metadata":{"id":"8_G06n07OSmF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1664673703706,"user":{"displayName":"Alvin Hew Xin Yao","userId":"07976192354382836143"},"user_tz":-480},"id":"H8idabIe3izX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c99c833-c8a5-4e32-fd76-0b55ac9e34a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Num of training samples =  493\n"]}],"source":["_dataset_dir = \"./food11\"\n","train_path = os.path.join(_dataset_dir,\"training\") #9866 items\n","train_paths = [os.path.join(train_path,x) for x in os.listdir(train_path) if x.endswith(\".jpg\")]\n","random.shuffle(train_paths) #DataLoader will also shuffle\n","label_percent = len(train_paths)//20 #only use 5% of the labels, avg ~40 for each category\n","print(\"Num of training samples = \", label_percent)\n","train_paths_wiflabel = train_paths[:label_percent]\n","train_paths_nolabel = train_paths[label_percent:]#[:300]\n","\n","val_path = os.path.join(_dataset_dir,\"validation\") #3430 items\n","val_paths = [os.path.join(val_path,x) for x in os.listdir(val_path) if x.endswith(\".jpg\")]#[:200]"]},{"cell_type":"code","source":["def label_distrib(paths):\n","  label_ct_dict = {}\n","  for fname in paths:\n","    label = fname.split(\"/\")[-1].split(\"_\")[0]\n","    label_ct_dict[label] = 1 if (label not in list(label_ct_dict.keys())) else (label_ct_dict[label] + 1)\n","  return label_ct_dict\n","\n","diction = label_distrib(train_paths_wiflabel)\n","plt.figure(figsize=(15,5))\n","plt.bar(diction.keys(), diction.values())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"Vl8dtdkxCh0P","executionInfo":{"status":"ok","timestamp":1664673703707,"user_tz":-480,"elapsed":16,"user":{"displayName":"Alvin Hew Xin Yao","userId":"07976192354382836143"}},"outputId":"b503627e-2ff7-4950-aea0-bc3875886c06"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BarContainer object of 11 artists>"]},"metadata":{},"execution_count":13},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x360 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["diction = label_distrib(val_paths)\n","plt.figure(figsize=(15,5))\n","plt.bar(diction.keys(), diction.values())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"id":"h1cIffI42MOV","executionInfo":{"status":"ok","timestamp":1664673704113,"user_tz":-480,"elapsed":416,"user":{"displayName":"Alvin Hew Xin Yao","userId":"07976192354382836143"}},"outputId":"652391b3-35c3-4989-ea41-3fa38e639af0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BarContainer object of 11 artists>"]},"metadata":{},"execution_count":14},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x360 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAA20AAAEvCAYAAADW/SmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUV0lEQVR4nO3df6xndX3n8de7XK0/2ojC7YSdwb0kErukiUgnlK5d08LagGOEbKzB7Fpi2J39A3dx26Q77T9Nk/1jTDa1NWlMiLiOuyqlqIEIsRKk2+wfUgelCqLrlB3KzAIzVcR2SWux7/3jHuyV3tu5d+Zez4d7H4/k5p7zOefe7/uezAw853u+36nuDgAAAGP6kbkHAAAAYG2iDQAAYGCiDQAAYGCiDQAAYGCiDQAAYGCiDQAAYGALcw+QJOeee24vLS3NPQYAAMAs7r///r/o7sXVjg0RbUtLSzl8+PDcYwAAAMyiqh5d65jbIwEAAAYm2gAAAAYm2gAAAAYm2gAAAAYm2gAAAAYm2gAAAAYm2gAAAAa2rmirqqNV9ZWqeqCqDk9rr6qqu6vqG9PnV07rVVXvr6ojVfXlqrpkK38AAACA7Wwjz7T9Qndf3N17p/0DSe7p7guT3DPtJ8lVSS6cPvYn+cBmDQsAALDTnMntkVcnOTRtH0pyzYr1j/Syzyc5u6rOO4PHAQAA2LHWG22d5LNVdX9V7Z/WdnX349P2E0l2Tdu7kzy24muPTWsAAABs0MI6z/u57j5eVT+R5O6q+trKg93dVdUbeeAp/vYnyatf/eqNfCnwArN04M65R9hyRw/um3sEADbAf5t4IVnXM23dfXz6fCLJp5JcmuTJ5257nD6fmE4/nuT8FV++Z1p7/ve8qbv3dvfexcXF0/8JAAAAtrFTRltVvbyqfvy57SS/mOTBJHckuW467bokt0/bdyT55eldJC9L8vSK2ygBAADYgPXcHrkryaeq6rnzP9bdn6mqLyS5taquT/JokrdP59+V5M1JjiR5Jsm7Nn1qAACAHeKU0dbdjyR53Srr30xyxSrrneSGTZkOAABghzuTt/wHAABgi4k2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgYk2AACAgS3MPQAAsH5LB+6ce4QtdfTgvrlHABiOZ9oAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGJtoAAAAGtu5oq6qzqupLVfXpaf+Cqrqvqo5U1e9X1Yun9R+d9o9Mx5e2ZnQAAIDtbyPPtN2Y5OEV++9N8r7ufk2Sp5JcP61fn+Spaf1903kAAACchnVFW1XtSbIvyQen/UpyeZLbplMOJblm2r562s90/IrpfAAAADZovc+0/U6SX0vyd9P+OUm+3d3PTvvHkuyetncneSxJpuNPT+cDAACwQaeMtqp6S5IT3X3/Zj5wVe2vqsNVdfjkyZOb+a0BAAC2jfU80/aGJG+tqqNJbsnybZG/m+TsqlqYztmT5Pi0fTzJ+UkyHX9Fkm8+/5t2903dvbe79y4uLp7RDwEAALBdnTLauvvXu3tPdy8luTbJ57r7Xye5N8nbptOuS3L7tH3HtJ/p+Oe6uzd1agAAgB3iTP6dtv+c5Feq6kiWX7N287R+c5JzpvVfSXLgzEYEAADYuRZOfcrf6+4/SvJH0/YjSS5d5Zy/TvJLmzAbAADAjncmz7QBAACwxUQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwBbmHgAAABjH0oE75x5hSx09uG/uETbMM20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAAD8++0wSby75oAALDZPNMGAAAwMNEGAAAwMNEGAAAwMNEGAAAwMNEGAAAwMNEGAAAwMNEGAAAwMNEGAAAwMNEGAAAwMNEGAAAwsIW5BwDYyZYO3Dn3CFvq6MF9p/V12/26JKd/bQDYeTzTBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMLBTRltVvaSq/qSq/rSqHqqq35rWL6iq+6rqSFX9flW9eFr/0Wn/yHR8aWt/BAAAgO1rPc+0/U2Sy7v7dUkuTnJlVV2W5L1J3tfdr0nyVJLrp/OvT/LUtP6+6TwAAABOwymjrZf91bT7oumjk1ye5LZp/VCSa6btq6f9TMevqKratIkBAAB2kHW9pq2qzqqqB5KcSHJ3kj9L8u3ufnY65ViS3dP27iSPJcl0/Okk56zyPfdX1eGqOnzy5Mkz+ykAAAC2qXVFW3d/r7svTrInyaVJfvJMH7i7b+ruvd29d3Fx8Uy/HQAAwLa0oXeP7O5vJ7k3yc8mObuqFqZDe5Icn7aPJzk/Sabjr0jyzU2ZFgAAYIdZz7tHLlbV2dP2S5O8KcnDWY63t02nXZfk9mn7jmk/0/HPdXdv5tAAAAA7xcKpT8l5SQ5V1VlZjrxbu/vTVfXVJLdU1X9J8qUkN0/n35zkv1fVkSTfSnLtFswNAACwI5wy2rr7y0lev8r6I1l+fdvz1/86yS9tynQAAAA73IZe0wYAAMAPl2gDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAYmGgDAAAY2MLcAwAAnKmlA3fOPcKWO3pw39wjADPxTBsAAMDARBsAAMDARBsAAMDARBsAAMDARBsAAMDARBsAAMDARBsAAMDARBsAAMDARBsAAMDARBsAAMDARBsAAMDAThltVXV+Vd1bVV+tqoeq6sZp/VVVdXdVfWP6/Mppvarq/VV1pKq+XFWXbPUPAQAAsF2t55m2Z5P8andflOSyJDdU1UVJDiS5p7svTHLPtJ8kVyW5cPrYn+QDmz41AADADnHKaOvux7v7i9P2XyZ5OMnuJFcnOTSddijJNdP21Uk+0ss+n+Tsqjpv0ycHAADYATb0mraqWkry+iT3JdnV3Y9Ph55Ismva3p3ksRVfdmxaAwAAYIPWHW1V9WNJPpHkPd39nZXHuruT9EYeuKr2V9Xhqjp88uTJjXwpAADAjrGuaKuqF2U52D7a3Z+clp987rbH6fOJaf14kvNXfPmeae0HdPdN3b23u/cuLi6e7vwAAADb2nrePbKS3Jzk4e7+7RWH7khy3bR9XZLbV6z/8vQukpcleXrFbZQAAABswMI6znlDkncm+UpVPTCt/UaSg0lurarrkzya5O3TsbuSvDnJkSTPJHnXpk4MAACwg5wy2rr7fyWpNQ5fscr5neSGM5wLAACAbPDdIwEAAPjhEm0AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADE20AAAADW5h7gJEtHbhz7hG21NGD++YeAQAAOAXRBgCwjflLaHjhc3skAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwEQbAADAwE4ZbVX1oao6UVUPrlh7VVXdXVXfmD6/clqvqnp/VR2pqi9X1SVbOTwAAMB2t55n2j6c5MrnrR1Ick93X5jknmk/Sa5KcuH0sT/JBzZnTAAAgJ3plNHW3X+c5FvPW746yaFp+1CSa1asf6SXfT7J2VV13mYNCwAAsNOc7mvadnX349P2E0l2Tdu7kzy24rxj0xoAAACn4YzfiKS7O0lv9Ouqan9VHa6qwydPnjzTMQAAALal0422J5+77XH6fGJaP57k/BXn7ZnW/oHuvqm793b33sXFxdMcAwAAYHtbOM2vuyPJdUkOTp9vX7H+7qq6JcnPJHl6xW2UbCNLB+6ce4QtdfTgvrlHAACAJOuItqr6eJKfT3JuVR1L8ptZjrVbq+r6JI8meft0+l1J3pzkSJJnkrxrC2YGAADYMU4Zbd39jjUOXbHKuZ3khjMdCgAAgGVn/EYkAAAAbB3RBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMDDRBgAAMLAtibaqurKqvl5VR6rqwFY8BgAAwE6w6dFWVWcl+b0kVyW5KMk7quqizX4cAACAnWArnmm7NMmR7n6ku7+b5JYkV2/B4wAAAGx7WxFtu5M8tmL/2LQGAADABlV3b+43rHpbkiu7+99O++9M8jPd/e7nnbc/yf5p97VJvr6pg7wwnZvkL+YeYlCuzepcl7W5NqtzXdbm2qzOdVmd67I212Z1rsvaXJtl/7S7F1c7sLAFD3Y8yfkr9vdMaz+gu29KctMWPP4LVlUd7u69c88xItdmda7L2lyb1bkua3NtVue6rM51WZtrszrXZW2uzaltxe2RX0hyYVVdUFUvTnJtkju24HEAAAC2vU1/pq27n62qdyf5wyRnJflQdz+02Y8DAACwE2zF7ZHp7ruS3LUV33ubc7vo2lyb1bkua3NtVue6rM21WZ3rsjrXZW2uzepcl7W5Nqew6W9EAgAAwObZite0AQAAsElE2yCq6uyquq2qvlZVD1fVz84909yq6rVV9cCKj+9U1XvmnmsUVfWfquqhqnqwqj5eVS+Ze6YRVNWN0zV5yK+Xv1dVL6mqP6mqP52uzW/NPdNIquqsqvpSVX167llGUlVHq+or05/Bh+eeZy5V9aGqOlFVD65Ye1VV3V1V35g+v3LOGUew2nUiqarzq+reqvrq9OfvjXPPNIqqurKqvl5VR6rqwNzzjEy0jeN3k3ymu38yyeuSPDzzPLPr7q9398XdfXGSn07yTJJPzTzWEKpqd5L/mGRvd/9Ult/059p5p5pfVf1Ukn+X5NIs/z56S1W9Zt6phvE3SS7v7tcluTjJlVV12cwzjeTG+HN3Lb8w/Vm8k9+O+8NJrnze2oEk93T3hUnumfZ3ug/nH14nkmeT/Gp3X5TksiQ3VNVFM880u6o6K8nvJbkqyUVJ3uG6rE20DaCqXpHkjUluTpLu/m53f3veqYZzRZI/6+5H5x5kIAtJXlpVC0leluT/zjzPCP5Zkvu6+5nufjbJ/0zyr2aeaQi97K+m3RdNH17UnKSq9iTZl+SDc8/CmLr7j5N863nLVyc5NG0fSnLND3WoAa1xnXa87n68u784bf9llv+CaPe8Uw3h0iRHuvuR7v5ukluy/PuKVYi2MVyQ5GSS/zbdnvPBqnr53EMN5tokH597iFF09/Ek/zXJnyd5PMnT3f3ZeacawoNJ/kVVnVNVL0vy5iTnzzzTMKZbAB9IciLJ3d1939wzDeJ3kvxakr+be5ABdZLPVtX9VbV/7mEGs6u7H5+2n0iya85heGGoqqUkr0/iz9/lcH1sxf6xiNk1ibYxLCS5JMkHuvv1Sf5f3GbxfdM/0v7WJH8w9yyjmF47cXWWg/+fJHl5Vf2beaeaX3c/nOS9ST6b5DNJHkjyvVmHGkh3f2+63XhPkkun20l3tKp6S5IT3X3/3LMM6ue6+5Is3750Q1W9ce6BRtTLb8XtmWv+UVX1Y0k+keQ93f2duefhhUW0jeFYkmMr/tb7tixHHMuuSvLF7n5y7kEG8i+T/J/uPtndf5vkk0n++cwzDaG7b+7un+7uNyZ5Ksn/nnum0Uy3X98brz1JkjckeWtVHc3yrTmXV9X/mHekcUzP6qe7T2T5NcWXzjvRUJ6sqvOSZPp8YuZ5GFhVvSjLwfbR7v7k3PMM4nh+8G6YPdMaqxBtA+juJ5I8VlWvnZauSPLVGUcazTvi1sjn+/Mkl1XVy6qqsvxrxpsoJKmqn5g+vzrLr2f72LwTjaGqFqvq7Gn7pUnelORr8041v+7+9e7e091LWb4N+3PdveOftU6Sqnp5Vf34c9tJfjHLtyCz7I4k103b1yW5fcZZGNj03+mbkzzc3b899zwD+UKSC6vqgumuqmuz/PuKVSzMPQDf9x+SfHT6RftIknfNPM8Qpv9ReFOSfz/3LCPp7vuq6rYkX8zyu1J9KclN8041jE9U1TlJ/jbJDd7U5/vOS3JoereuH0lya3d7e3v+MbuSfGr5/zezkORj3f2ZeUeaR1V9PMnPJzm3qo4l+c0kB5PcWlXXJ3k0ydvnm3AMq12n7r553qmG8IYk70zylel1xUnyG91914wzza67n62qdyf5wyy/C/aHuvuhmccaVi3fhg0AAMCI3B4JAAAwMNEGAAAwMNEGAAAwMNEGAAAwMNEGAAAwMNEGAAAwMNEGAAAwMNEGAAAwsP8P2jhAB7NZpUsAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["def get_pseudo_labels(data_loader, model, threshold):\n","  softmax = nn.Softmax(dim=-1)\n","  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","  model.eval()\n","\n","  #labelled_x, labelled_y, prob_lst, label_lst = [], [], [], []\n","  for i, batch in enumerate(tqdm(data_loader)):\n","    batch = next(iter(data_loader))\n","    imgs, label = batch\n","    with torch.no_grad():\n","      logits = model(imgs.to(device))\n","    probs = softmax(logits) #[64, 11]\n","    #prob, pred = np.amax(probs, axis=-1), np.argmax(probs, axis=-1) #shape = (64,)\n","    prob, pred = torch.max(probs, dim=1)\n","    prob, pred = prob.cpu(), pred.cpu()\n","    imgs, label = imgs.cpu(), label.cpu()\n","\n","    idxs = torch.where((prob>threshold[0]) & (prob < threshold[1]))[0]\n","    #https://stackoverflow.com/questions/67163825/the-truth-value-of-an-array-with-more-than-one-element-is-ambiguous-error-pyt\n","    #all_lst = np.array([[imgs.cpu()[i], label.cpu()[i], prob[i], pred[i]] for i in idxs]) #list comprehension\n","    \n","    #https://discuss.pytorch.org/t/pytorch-equivalent-of-numpy-take/108797/2\n","    labelled_x = torch.index_select(imgs,0,idxs) if i==0 else torch.cat((labelled_x, torch.index_select(imgs,0,idxs)))\n","    labelled_y = torch.index_select(label,0,idxs) if i==0 else torch.cat((labelled_y, torch.index_select(label,0,idxs)))\n","    prob_arr = torch.index_select(prob,0,idxs) if i==0 else torch.cat((prob_arr, torch.index_select(prob,0,idxs)))\n","    pred_arr = torch.index_select(pred,0,idxs) if i==0 else torch.cat((pred_arr, torch.index_select(pred,0,idxs)))\n","    #pred_arr = np.take(pred, idxs, axis=0) if i==0 else torch.cat((pred_arr, np.take(pred, idxs, axis=0)))\n","\n","  labelled_x, pred_arr = labelled_x[:label_percent//2], pred_arr[:label_percent//2]\n","  print(\"labelled_x.shape = \", labelled_x.shape)\n","  print(\"pred_lst.shape = \", pred_arr.shape)\n","  print(\"[Info] \" + str(labelled_x.shape[0]) + \" imgs added as pseudo label\")\n","\n","  ds = CreateDataset(labelled_x, pred_arr, transform=train_tfm) #use predicted labels as pseudo\n","  view_img(labelled_x.cpu().numpy(), labelled_y.cpu().numpy(), \n","           prob_arr.cpu().numpy(), pred_arr.cpu().numpy())\n","  # Turn off eval mode\n","  model.train()\n","  return ds"],"metadata":{"id":"msb4-WfAw1kV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2_OeWtstVaVO"},"outputs":[],"source":["batch_size = 64 #Greater batch size --> more stable gradient.\n","semi = True\n","#_dataset_dir = \"./food11\"\n","# The argument \"loader\" tells how torchvision reads the data.\n","#train_set = FoodDataset(os.path.join(_dataset_dir,\"training\"), tfm=train_tfm)\n","train_set = FoodDataset(train_paths_wiflabel, tfm=train_tfm)\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n","if semi:\n","  train_nolbl_set = FoodDataset(train_paths_nolabel, tfm=train_tfm) #still include labels for visualization, but will remove it in get_pseudo_labels()\n","  train_nolbl_loader = DataLoader(train_nolbl_set, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n","#valid_set = FoodDataset(os.path.join(_dataset_dir,\"validation\"), tfm=test_tfm)\n","valid_set = FoodDataset(val_paths, tfm=test_tfm)\n","valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RKlNZqm_14__"},"outputs":[],"source":["class_names = {0:'Bread', 1:'Dairy product', 2:'Dessert', 3:'Egg', 4:'Fried food', 5:'Meat', 6:'Noodles/Pasta', 7:'Rice', 8:'Seafood', 9:'Soup', 10:'Vegetable/Fruit'}"]},{"cell_type":"code","source":["from skimage.segmentation import slic\n","!pip install lime==0.1.1.37\n","from lime import lime_image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q8q7hAsbCwkn","executionInfo":{"status":"ok","timestamp":1664673709074,"user_tz":-480,"elapsed":4966,"user":{"displayName":"Alvin Hew Xin Yao","userId":"07976192354382836143"}},"outputId":"3e592931-ea63-4781-8575-1e2fc709f1cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: lime==0.1.1.37 in /usr/local/lib/python3.7/dist-packages (0.1.1.37)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime==0.1.1.37) (3.2.2)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime==0.1.1.37) (1.0.2)\n","Requirement already satisfied: progressbar in /usr/local/lib/python3.7/dist-packages (from lime==0.1.1.37) (2.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime==0.1.1.37) (1.21.6)\n","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime==0.1.1.37) (0.18.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime==0.1.1.37) (1.7.3)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.1.1.37) (2.6.3)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.1.1.37) (2.9.0)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.1.1.37) (7.1.2)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.1.1.37) (2021.11.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime==0.1.1.37) (1.3.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.1.1.37) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.1.1.37) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.1.1.37) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime==0.1.1.37) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->lime==0.1.1.37) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->lime==0.1.1.37) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime==0.1.1.37) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime==0.1.1.37) (3.1.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AxWCt0cU1-O3"},"outputs":[],"source":["def predict(input):\n","    # input: numpy array, (batches, height, width, channels)                                                                                                                                                     \n","    model.eval()                                                                                                                                                             \n","    input = torch.FloatTensor(input).permute(0, 3, 1, 2)                                                                                                            \n","    # pytorch tensor, (batches, channels, height, width)\n","    output = model(input.cuda())                                                                                                                                             \n","    return output.detach().cpu().numpy()                                                                                                                              \n","                                                                                                                                                                             \n","def segmentation(input):\n","    # split the image into 200 pieces with the help of segmentaion from skimage                                                                                                                   \n","    return slic(input, n_segments=200, compactness=1, sigma=1, start_label=1) \n","\n","\n","def view_img(images, labels, prob=None, pred=None):\n","    #std = np.array([0.2708, 0.2733, 0.2718])\n","    #mean = np.array([0.5462, 0.4369, 0.3265])\n","    plt.figure(figsize=(30, 15))\n","    for i in range(min(32, int(images.shape[0]))): # show at most 32 images\n","      ax = plt.subplot(4, 8, i + 1)\n","      ax.axis('off') # turn axis off for each subplot\n","      try:\n","        inp = images[i].numpy()\n","      except:\n","        inp = images[i]\n","    \n","      #inp = np.array([inp[i]*std[i] + mean[i] for i in range(3)]) \n","      inp = inp.transpose((1, 2, 0))\n","\n","      #lime: Green --> positive correlation; Red --> negative correlation\n","      explainer = lime_image.LimeImageExplainer()                                                                                                                              \n","      explaination = explainer.explain_instance(\n","          image=inp.astype(np.double), classifier_fn=predict, segmentation_fn=segmentation, top_labels=11)\n","      # doc: https://lime-ml.readthedocs.io/en/latest/lime.html?highlight=explain_instance#lime.lime_image.LimeImageExplainer.explain_instance\n","      #print(int(labels[i]))\n","      lime_img, mask = explaination.get_image_and_mask(\n","          label=int(labels[i]), positive_only=False, hide_rest=False, num_features=11, min_weight=0.05) #label=label.item()\n","\n","      #plt.imshow(np.clip(inp, 0, 1))\n","      #plt.imshow(inp)\n","      plt.imshow(lime_img)\n","\n","      txt = str(int(labels[i])) + '_' + class_names[int(labels[i])]\n","      color = 'black'\n","      if np.array(prob).all():\n","        txt += '\\n{:.2f}%'.format(float(prob[i])*100) + ' ' + class_names[int(pred[i])]\n","        color = 'green' if (int(labels[i])==int(pred[i])) else 'red'\n","\n","      plt.title(txt, color=color)\n","      #plt.axis(\"off\")\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QbCFQpme2CIt"},"outputs":[],"source":["#images, labels = next(iter(train_loader))\n","#print(images.shape,labels.shape) #torch.Size([64, 3, 128, 128]) torch.Size([64])\n","#view_img(images, labels)"]},{"cell_type":"markdown","source":["Ori:\n","![1.png](data:image/png;base64,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)"],"metadata":{"id":"aNPM4gAwf2nL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q4K8fib01Wuk"},"outputs":[],"source":["#class Classifier(nn.Module):"]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","#model = Classifier().to(device) # Initialize model.\n","#model = torchvision.models.resnext101_32x8d(pretrained=False).to(device)   # Num Params =  88791336\n","model = torchvision.models.efficientnet_v2_s(pretrained=True)#.to(device)  # Num Params =  21458488\n","#print(model.classifier) #https://discuss.pytorch.org/t/finetuning-efficientnet-in-pytorch/89852\n","#[[name, module] for name, module in model.named_modules()] #https://discuss.pytorch.org/t/how-to-get-the-module-names-of-nn-sequential/39682\n","#model = nn.Sequential(model, nn.Linear(model.fc.in_features, 11)) #add layer\n","#model.classifier = nn.Sequential(nn.Dropout(p=0.2, inplace=True), nn.Linear(1280, 11)) #replace layer \n","model.classifier[1] = nn.Linear(model.classifier[1].in_features, 11) #https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n","model = model.to(device)\n","#print(model)\n","print('Num Params = ', sum(p.numel() for p in model.parameters() if p.requires_grad)) \n","#default: all of the parameters have .requires_grad=True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_v0d574zZApz","executionInfo":{"status":"ok","timestamp":1664673712017,"user_tz":-480,"elapsed":2954,"user":{"displayName":"Alvin Hew Xin Yao","userId":"07976192354382836143"}},"outputId":"b99c89fe-daf9-46fe-9a28-a0ce8c6b2101"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n","  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n","/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_V2_S_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Num Params =  20191579\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"zbVkfIFhVaVO","executionInfo":{"status":"ok","timestamp":1664675199029,"user_tz":-480,"elapsed":1487019,"user":{"displayName":"Alvin Hew Xin Yao","userId":"07976192354382836143"}},"outputId":"96311d74-b799-45fe-f6a2-5d8a1958a045"},"outputs":[],"source":["n_epochs = 400\n","patience = 3 # If no improvement in 'patience' epochs, early stop\n","\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5) \n","\n","stale, best_acc, improvement, prev_val_acc, semi_ct = 0, 0, 100., 0., 0\n","for epoch in range(n_epochs):\n","\n","    if semi and improvement < 2.0*(1/(semi_ct+1)) and improvement > -3.:\n","      semi_ct += 1\n","      prev_val_acc = 0. #wait 1 ep for semi\n","      print(\"improvement = {:.6f}%\".format(improvement))\n","      pseudo_set = get_pseudo_labels(train_nolbl_loader, model, threshold=[0.85, 0.999])\n","      concat_dataset = ConcatDataset([train_set, pseudo_set])\n","      train_loader = DataLoader(concat_dataset, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n","\n","    # ---------- Training ----------\n","    model.train()\n","    train_loss, train_accs = [], []\n","    for batch in tqdm(train_loader):\n","        imgs, labels = batch\n","        logits = model(imgs.to(device)) # Forward the data. (Make sure data and model are on the same device.)\n","        loss = criterion(logits, labels.to(device)) #softmax calculated automatically\n","\n","        # Gradients stored in the parameters in the previous step should be cleared out first.\n","        optimizer.zero_grad()\n","        loss.backward() #compute grad for params\n","        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10) # Clip the gradient norms for stable training.\n","        optimizer.step() # Update the parameters with computed gradients.\n","\n","        # Compute the accuracy for current batch.\n","        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","\n","        train_loss.append(loss.item())\n","        train_accs.append(acc)\n","        \n","    train_loss = sum(train_loss) / len(train_loss)\n","    train_acc = sum(train_accs) / len(train_accs)\n","    #print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n","\n","    # ---------- Validation ----------\n","    model.eval() # Make sure the model is in eval mode so that some modules like dropout are disabled \n","    valid_loss, valid_accs = [], []\n","    for batch in tqdm(valid_loader):\n","        imgs, labels = batch\n","        #imgs = imgs.half()\n","        # We don't need gradient in validation.\n","        # Using torch.no_grad() accelerates the forward process.\n","        with torch.no_grad():\n","            logits = model(imgs.to(device))\n","        loss = criterion(logits, labels.to(device))\n","        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","        valid_loss.append(loss.item())\n","        valid_accs.append(acc)\n","        #break\n","    # The average loss and accuracy for entire validation set is the average of the recorded values.\n","    valid_loss = sum(valid_loss) / len(valid_loss)\n","    valid_acc = sum(valid_accs) / len(valid_accs)\n","    #print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n","    #with open(f\"./{_exp_name}_log.txt\",\"a\"):\n","    out = \"[{:03d}/{:03d}] train_loss: {:.3f}, train_acc: {:3.2f}% | val_loss: {:.3f}, val_acc: {:3.2f}%\".format(\n","          epoch + 1, n_epochs, train_loss, train_acc*100, valid_loss, valid_acc*100)\n","    print(out)\n","    with open(f\"./{_exp_name}_log.txt\",\"a\") as f:\n","      print(out, file=f)\n","    \n","    #for pseudo\n","    improvement = valid_acc*100 - prev_val_acc\n","    prev_val_acc = valid_acc*100\n","    \"\"\"\n","    if valid_acc > best_acc:\n","        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n","            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n","    else:\n","        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n","            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n","    \"\"\"\n","    if valid_acc > best_acc:\n","        print(f\"Best model found at epoch {epoch}, saving model\")\n","        torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n","        best_acc = valid_acc\n","        stale = 0\n","    else:\n","        stale += 1\n","        if stale >= patience:\n","            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n","            break\n","    print(\"\")"]},{"cell_type":"code","source":["#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","#model = torchvision.models.efficientnet_v2_s(pretrained=False).to(device)\n","model_best = model#Classifier().to(device)\n","model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n","model_best.eval()\n","\n","softmax = nn.Softmax(dim=-1)\n","imgs, labels = next(iter(valid_loader))\n","with torch.no_grad():\n","    logits = model(imgs.to(device))\n","probs = softmax(logits)\n","prob, pred = torch.max(probs, dim=1)\n","probs.shape\n","view_img(imgs.cpu(), labels.cpu(), prob.cpu(), pred.cpu())\n"],"metadata":{"id":"rIzGJcYzeUiD","executionInfo":{"status":"ok","timestamp":1664675405779,"user_tz":-480,"elapsed":206767,"user":{"displayName":"Alvin Hew Xin Yao","userId":"07976192354382836143"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a133523a-d9f0-4608-cc9f-6f2b24717bb9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G31uyjpvVaVP"},"source":["# Testing and generate prediction CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1664675405780,"user":{"displayName":"Alvin Hew Xin Yao","userId":"07976192354382836143"},"user_tz":-480},"id":"B9QNdHIXVaVP","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"007bbcb5-6671-4dea-caab-a9f81b66788c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntest_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=test_tfm)\\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}],"source":["\"\"\"\n","test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=test_tfm)\n","test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1664675405782,"user":{"displayName":"Alvin Hew Xin Yao","userId":"07976192354382836143"},"user_tz":-480},"id":"bpLtxx5FVaVP","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"3b5f4c87-f64c-49b0-fd2b-12b4c7113406"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nmodel_best = torchvision.models.resnext101_32x8d(pretrained=False).to(device)#Classifier().to(device)\\nmodel_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\\nmodel_best.eval()\\nprediction = []\\nwith torch.no_grad():\\n    for data,_ in test_loader:\\n        test_pred = model_best(data.to(device))\\n        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\\n        prediction += test_label.squeeze().tolist()\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":26}],"source":["\"\"\"\n","model_best = torchvision.models.resnext101_32x8d(pretrained=False).to(device)#Classifier().to(device)\n","model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n","model_best.eval()\n","prediction = []\n","with torch.no_grad():\n","    for data,_ in test_loader:\n","        test_pred = model_best(data.to(device))\n","        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n","        prediction += test_label.squeeze().tolist()\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"jRDuJsGCgxCO"},"source":["## References\n","[1] https://www.kaggle.com/c/ml2022spring-hw3b/code?competitionId=34954&sortBy=dateCreated (We strongly recommend that you run with Kaggle for this homework (HW3))\n","\n","[2] https://colab.research.google.com/drive/15hMu9YiYjE_6HY99UXon2vKGk2KwugWu\n"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}